{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132482\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import multiprocessing as mp\n",
    "f = open(\"textfilter3.csv\", \"rb\")\n",
    "g = nx.read_edgelist(f)\n",
    "num_edges = g.number_of_edges()\n",
    "num_nodes = g.number_of_nodes()\n",
    "f.close()\n",
    "\n",
    "newgraph = nx.DiGraph()\n",
    "newgraph.add_edges_from(g.edges(), positive=\"True\") \n",
    "nx.write_edgelist(newgraph, \"newgraph3.txt\", data=['positive'])\n",
    "\n",
    "num_sample_edges = int(math.floor(0.1 * num_edges))  # positive sample data\n",
    "print(num_sample_edges)\n",
    "sample_edges = random.sample(newgraph.edges(), num_sample_edges)\n",
    "sample_g = nx.Graph()\n",
    "sample_g.add_edges_from(sample_edges, positive = \"True\")\n",
    "nx.write_edgelist(sample_g, \"positivesample3.txt\", data=['positive'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_negative = open(\"negativesample3.txt\",\"w\")  # make negative sample the same as num_sample_edges(positive sample data) \n",
    "# and add it to sample_g, thus sample_g has data amount of 2*num_sample_edges(2 Ã— 132482 records of edges)\n",
    "i = 0\n",
    "while i < num_sample_edges:  #132482 records\n",
    "    edge = random.sample(sample_g.nodes(), 2)\n",
    "    try:\n",
    "        shortest_path = nx.shortest_path_length(sample_g,source=edge[0],target=edge[1])\n",
    "        if shortest_path !=1:\n",
    "            sample_g.add_edge(edge[0],edge[1], positive=\"False\")   #add neagtive case            \n",
    "            i += 1\n",
    "    except:\n",
    "        sample_g.add_edge(edge[0],edge[1], positive=\"False\") \n",
    "        i +=1   \n",
    "    fake_negative.write(str(edge[0])+\" \"+str(edge[1])+\" False\\n\")\n",
    "fake_negative.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264964\n"
     ]
    }
   ],
   "source": [
    "print(sample_g.number_of_edges())\n",
    "nx.write_edgelist(sample_g, \"allsample3.txt\", delimiter=',' , data = ['positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2184483</td>\n",
       "      <td>1300190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3151356</td>\n",
       "      <td>1452193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1579396</td>\n",
       "      <td>193159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1406432</td>\n",
       "      <td>2481036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2389638</td>\n",
       "      <td>593017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source   target\n",
       "0  2184483  1300190\n",
       "1  3151356  1452193\n",
       "2  1579396   193159\n",
       "3  1406432  2481036\n",
       "4  2389638   593017"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "f = open(\"testdata.csv\", \"rb\")\n",
    "dftest = pd.read_table('testdata.csv', sep = '\\t', names = [\"source\", \"target\"])\n",
    "dftest[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = nx.pagerank(newgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_table('trainingdataframe.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sourcepr = []\n",
    "targetpr = []\n",
    "for s in df[\"source\"]:\n",
    "    sourcepr.append(pr[str(s)])\n",
    "for s in df[\"target\"]:\n",
    "    targetpr.append(pr[str(s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>positive</th>\n",
       "      <th>Common</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>PreferentialAttachment</th>\n",
       "      <th>AdamicAdar</th>\n",
       "      <th>ResourceAllocation</th>\n",
       "      <th>Sourcepr</th>\n",
       "      <th>Targetpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2789436</td>\n",
       "      <td>2203730</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "      <td>0.112565</td>\n",
       "      <td>36036</td>\n",
       "      <td>7.807700</td>\n",
       "      <td>0.202805</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2789436</td>\n",
       "      <td>1467962</td>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>67760</td>\n",
       "      <td>10.368729</td>\n",
       "      <td>0.354982</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2789436</td>\n",
       "      <td>812874</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>0.076705</td>\n",
       "      <td>21868</td>\n",
       "      <td>4.776423</td>\n",
       "      <td>0.141276</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2789436</td>\n",
       "      <td>3183013</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>0.075988</td>\n",
       "      <td>14168</td>\n",
       "      <td>5.283508</td>\n",
       "      <td>0.285230</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   source   target  positive  Common   Jaccard  \\\n",
       "0           0  2789436  2203730      True      43  0.112565   \n",
       "1           1  2789436  1467962      True      54  0.113924   \n",
       "2           2  2789436   812874      True      27  0.076705   \n",
       "3           3  2789436  3183013      True      25  0.075988   \n",
       "\n",
       "   PreferentialAttachment  AdamicAdar  ResourceAllocation  Sourcepr  Targetpr  \n",
       "0                   36036    7.807700            0.202805  0.000004  0.000006  \n",
       "1                   67760   10.368729            0.354982  0.000004  0.000006  \n",
       "2                   21868    4.776423            0.141276  0.000004  0.000005  \n",
       "3                   14168    5.283508            0.285230  0.000004  0.000006  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sourcepr\"] = sourcepr\n",
    "df[\"Targetpr\"] = targetpr\n",
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>positive</th>\n",
       "      <th>Common</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>PreferentialAttachment</th>\n",
       "      <th>AdamicAdar</th>\n",
       "      <th>ResourceAllocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2789436</td>\n",
       "      <td>2203730</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "      <td>0.112565</td>\n",
       "      <td>36036</td>\n",
       "      <td>7.807700</td>\n",
       "      <td>0.202805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2789436</td>\n",
       "      <td>1467962</td>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>67760</td>\n",
       "      <td>10.368729</td>\n",
       "      <td>0.354982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   source   target  positive  Common   Jaccard  \\\n",
       "0           0  2789436  2203730      True      43  0.112565   \n",
       "1           1  2789436  1467962      True      54  0.113924   \n",
       "\n",
       "   PreferentialAttachment  AdamicAdar  ResourceAllocation  \n",
       "0                   36036    7.807700            0.202805  \n",
       "1                   67760   10.368729            0.354982  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.drop(df.columns[[0,1]], axis=1, inplace=True)\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>PreferentialAttachment</th>\n",
       "      <th>AdamicAdar</th>\n",
       "      <th>ResourceAllocation</th>\n",
       "      <th>Sourcepr</th>\n",
       "      <th>Targetpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>264964.000000</td>\n",
       "      <td>264964.000000</td>\n",
       "      <td>2.649640e+05</td>\n",
       "      <td>264964.000000</td>\n",
       "      <td>264964.000000</td>\n",
       "      <td>264964.000000</td>\n",
       "      <td>264964.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.787726</td>\n",
       "      <td>0.016103</td>\n",
       "      <td>4.194262e+04</td>\n",
       "      <td>1.711725</td>\n",
       "      <td>0.051195</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35.713417</td>\n",
       "      <td>0.037162</td>\n",
       "      <td>1.664428e+05</td>\n",
       "      <td>6.869503</td>\n",
       "      <td>0.263697</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.440000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>2.022300e+04</td>\n",
       "      <td>1.218961</td>\n",
       "      <td>0.024060</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1721.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.660485e+06</td>\n",
       "      <td>345.763825</td>\n",
       "      <td>13.814983</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Common        Jaccard  PreferentialAttachment     AdamicAdar  \\\n",
       "count  264964.000000  264964.000000            2.649640e+05  264964.000000   \n",
       "mean        9.787726       0.016103            4.194262e+04       1.711725   \n",
       "std        35.713417       0.037162            1.664428e+05       6.869503   \n",
       "min         0.000000       0.000000            1.000000e+00       0.000000   \n",
       "25%         0.000000       0.000000            1.400000e+02       0.000000   \n",
       "50%         0.000000       0.000000            1.440000e+03       0.000000   \n",
       "75%         7.000000       0.016667            2.022300e+04       1.218961   \n",
       "max      1721.000000       1.000000            7.660485e+06     345.763825   \n",
       "\n",
       "       ResourceAllocation       Sourcepr       Targetpr  \n",
       "count       264964.000000  264964.000000  264964.000000  \n",
       "mean             0.051195       0.000013       0.000010  \n",
       "std              0.263697       0.000021       0.000015  \n",
       "min              0.000000       0.000004       0.000004  \n",
       "25%              0.000000       0.000004       0.000004  \n",
       "50%              0.000000       0.000006       0.000005  \n",
       "75%              0.024060       0.000010       0.000008  \n",
       "max             13.814983       0.000279       0.000279  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>PreferentialAttachment</th>\n",
       "      <th>AdamicAdar</th>\n",
       "      <th>ResourceAllocation</th>\n",
       "      <th>Sourcepr</th>\n",
       "      <th>Targetpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.112565</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.022581</td>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.006048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031377</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.029988</td>\n",
       "      <td>0.025695</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015689</td>\n",
       "      <td>0.076705</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.013814</td>\n",
       "      <td>0.010226</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.004754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Common   Jaccard  PreferentialAttachment  AdamicAdar  ResourceAllocation  \\\n",
       "0  0.024985  0.112565                0.004704    0.022581            0.014680   \n",
       "1  0.031377  0.113924                0.008845    0.029988            0.025695   \n",
       "2  0.015689  0.076705                0.002855    0.013814            0.010226   \n",
       "\n",
       "   Sourcepr  Targetpr  \n",
       "0   0.00044  0.006048  \n",
       "1   0.00044  0.009100  \n",
       "2   0.00044  0.004754  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm = df[['Common', 'Jaccard', \"PreferentialAttachment\", \"AdamicAdar\", \"ResourceAllocation\",\"Sourcepr\",\"Targetpr\"]].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df_norm[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>Common</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>PreferentialAttachment</th>\n",
       "      <th>AdamicAdar</th>\n",
       "      <th>ResourceAllocation</th>\n",
       "      <th>Sourcepr</th>\n",
       "      <th>Targetpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.264289</td>\n",
       "      <td>0.392264</td>\n",
       "      <td>0.236218</td>\n",
       "      <td>0.241358</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.037358</td>\n",
       "      <td>0.087551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Common</th>\n",
       "      <td>0.264289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557371</td>\n",
       "      <td>0.873392</td>\n",
       "      <td>0.994626</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>-0.093883</td>\n",
       "      <td>-0.043672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard</th>\n",
       "      <td>0.392264</td>\n",
       "      <td>0.557371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.317367</td>\n",
       "      <td>0.563675</td>\n",
       "      <td>0.600359</td>\n",
       "      <td>-0.086978</td>\n",
       "      <td>-0.005284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PreferentialAttachment</th>\n",
       "      <td>0.236218</td>\n",
       "      <td>0.873392</td>\n",
       "      <td>0.317367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.868294</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>-0.091062</td>\n",
       "      <td>-0.023363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdamicAdar</th>\n",
       "      <td>0.241358</td>\n",
       "      <td>0.994626</td>\n",
       "      <td>0.563675</td>\n",
       "      <td>0.868294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921255</td>\n",
       "      <td>-0.082796</td>\n",
       "      <td>-0.037226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResourceAllocation</th>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>0.600359</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>0.921255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047076</td>\n",
       "      <td>-0.006804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sourcepr</th>\n",
       "      <td>0.037358</td>\n",
       "      <td>-0.093883</td>\n",
       "      <td>-0.086978</td>\n",
       "      <td>-0.091062</td>\n",
       "      <td>-0.082796</td>\n",
       "      <td>-0.047076</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Targetpr</th>\n",
       "      <td>0.087551</td>\n",
       "      <td>-0.043672</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.023363</td>\n",
       "      <td>-0.037226</td>\n",
       "      <td>-0.006804</td>\n",
       "      <td>-0.041111</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        positive    Common   Jaccard  PreferentialAttachment  \\\n",
       "positive                1.000000  0.264289  0.392264                0.236218   \n",
       "Common                  0.264289  1.000000  0.557371                0.873392   \n",
       "Jaccard                 0.392264  0.557371  1.000000                0.317367   \n",
       "PreferentialAttachment  0.236218  0.873392  0.317367                1.000000   \n",
       "AdamicAdar              0.241358  0.994626  0.563675                0.868294   \n",
       "ResourceAllocation      0.190700  0.884286  0.600359                0.758920   \n",
       "Sourcepr                0.037358 -0.093883 -0.086978               -0.091062   \n",
       "Targetpr                0.087551 -0.043672 -0.005284               -0.023363   \n",
       "\n",
       "                        AdamicAdar  ResourceAllocation  Sourcepr  Targetpr  \n",
       "positive                  0.241358            0.190700  0.037358  0.087551  \n",
       "Common                    0.994626            0.884286 -0.093883 -0.043672  \n",
       "Jaccard                   0.563675            0.600359 -0.086978 -0.005284  \n",
       "PreferentialAttachment    0.868294            0.758920 -0.091062 -0.023363  \n",
       "AdamicAdar                1.000000            0.921255 -0.082796 -0.037226  \n",
       "ResourceAllocation        0.921255            1.000000 -0.047076 -0.006804  \n",
       "Sourcepr                 -0.082796           -0.047076  1.000000 -0.041111  \n",
       "Targetpr                 -0.037226           -0.006804 -0.041111  1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20a7b285b00>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcgAAAFnCAYAAAAi69nRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAtSkqQZFqQkSTMsSEmSZrwBmvALxrzniioAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20a2760c630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "corr = df.corr()\n",
    "# plot the heatmap\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>PreferentialAttachment</th>\n",
       "      <th>AdamicAdar</th>\n",
       "      <th>ResourceAllocation</th>\n",
       "      <th>Sourcepr</th>\n",
       "      <th>Targetpr</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.112565</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.022581</td>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031377</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.029988</td>\n",
       "      <td>0.025695</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015689</td>\n",
       "      <td>0.076705</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.013814</td>\n",
       "      <td>0.010226</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Common   Jaccard  PreferentialAttachment  AdamicAdar  ResourceAllocation  \\\n",
       "0  0.024985  0.112565                0.004704    0.022581            0.014680   \n",
       "1  0.031377  0.113924                0.008845    0.029988            0.025695   \n",
       "2  0.015689  0.076705                0.002855    0.013814            0.010226   \n",
       "\n",
       "   Sourcepr  Targetpr  positive  \n",
       "0   0.00044  0.006048      True  \n",
       "1   0.00044  0.009100      True  \n",
       "2   0.00044  0.004754      True  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df[['positive']]\n",
    "df = pd.concat([df_norm, target], axis=1)\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "from sklearn.metrics import accuracy_score\n",
    "training = train[['Common', 'Jaccard', \"PreferentialAttachment\", \"AdamicAdar\", \"ResourceAllocation\"]]\n",
    "training_labels = train['positive']\n",
    "testing = test[['Common', 'Jaccard', \"PreferentialAttachment\", \"AdamicAdar\", \"ResourceAllocation\"]]\n",
    "testing_labels = test['positive']\n",
    "training1 = train[['Common', \"AdamicAdar\"]]\n",
    "training_labels1 = train['positive']\n",
    "testing1 = test[['Common', \"AdamicAdar\"]]\n",
    "testing_labels1 = test['positive']\n",
    "training2 = train[['Jaccard', 'PreferentialAttachment']]\n",
    "training_labels2 = train['positive']\n",
    "testing2 = test[['Jaccard', 'PreferentialAttachment']]\n",
    "testing_labels2 = test['positive']\n",
    "training3 = train[['Common', 'Jaccard', \"PreferentialAttachment\", \"AdamicAdar\"]]\n",
    "training_labels3 = train['positive']\n",
    "testing3 = test[['Common', 'Jaccard', \"PreferentialAttachment\", \"AdamicAdar\"]]\n",
    "testing_labels3 = test['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "def mySvm(training, training_labels, testing, testing_labels):\n",
    "    #Support Vector Machine\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(training, training_labels)\n",
    "    print (\"+++++++++ Finishing training the SVM classifier ++++++++++++\")\n",
    "    result = clf.predict(testing)\n",
    "    print (\"SVM accuracy:\", accuracy_score(testing_labels, result))\n",
    "\n",
    "def myTree(training, training_labels, testing, testing_labels):\n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    result = clf.fit(training, training_labels).predict(testing)\n",
    "    print (\"+++++++++ Finishing training the Decision Tree classifier ++++++++++++\")\n",
    "    print (\"Random Forest accuracy:\", accuracy_score(testing_labels, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++ Finishing training the SVM classifier ++++++++++++\n",
      "SVM accuracy: 0.838180903258\n",
      "+++++++++ Finishing training the Decision Tree classifier ++++++++++++\n",
      "Random Forest accuracy: 0.830695684992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "mySvm(training1, training_labels1, testing1, testing_labels1)\n",
    "myTree(training1, training_labels1, testing1, testing_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False False False False]\n",
      "[2 1 1 3 4 5 6]\n",
      "[ 0.1410962   0.0935227   0.27872003  0.13479721  0.06637201  0.14626355\n",
      "  0.13922832]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 2)\n",
    "rfe = rfe.fit(training, training_labels)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(training, training_labels)\n",
    "# display the relative importance of each attribute based on extra classifier is 'Common', 'Jaccard', \"AdamicAdar\"\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score list: [  979.42336549  2435.26875589   891.45653541   859.64149836   660.29515642\n",
      "    43.87494122   177.73808969]\n",
      "Feature list: Index(['Common', 'Jaccard', 'PreferentialAttachment', 'AdamicAdar',\n",
      "       'ResourceAllocation', 'Sourcepr', 'Targetpr'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "# find best scored 5 features\n",
    "select_feature = SelectKBest(chi2, k=3).fit(training, training_labels)\n",
    "print('Score list:', select_feature.scores_)\n",
    "print('Feature list:', training.columns)\n",
    "# The same best features are 'Common','PreferentialAttachment', 'AdamicAdar'\n",
    "# Thus we only choose 3 features as siginificant attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression validation data accuracy: 0.823348848912\n",
      "LogisticRegression development data accuracy: 0.822783786407\n",
      "Raw AUC score: 0.822767611633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cheryl Zhang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import grid_search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "log = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\n",
    "GridSearchCV(cv=None,\n",
    "             estimator=LogisticRegression(C=1.0, intercept_scaling=1,   \n",
    "               dual=False, fit_intercept=True, penalty='l2', tol=0.0001),\n",
    "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]})\n",
    "log = log.fit(training1, training_labels1)\n",
    "resulttesting = log.predict(testing1)\n",
    "resutlttraining = log.predict(training1)\n",
    "print (\"LogisticRegression validation data accuracy:\", accuracy_score(testing_labels1, resulttesting))\n",
    "print (\"LogisticRegression development data accuracy:\", accuracy_score(training_labels1, resutlttraining))\n",
    "best_parameters, score, _ = max(log.grid_scores_, key=lambda x: x[1])\n",
    "print('Raw AUC score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1000\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=5, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "RFR = RandomForestRegressor()\n",
    "parameters = {'n_estimators': [5, 10, 100],\n",
    "              #'criterion': ['mse'],\n",
    "              #'max_depth': [5, 10, 15], \n",
    "              #'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1,5]\n",
    "             }\n",
    "grid_obj = GridSearchCV(RFR, parameters,\n",
    "                        cv=5, #Determines the cross-validation splitting strategy /to specify the number of folds in a (Stratified)KFold\n",
    "                        n_jobs=-1, #Number of jobs to run in parallel\n",
    "                        verbose=1)\n",
    "grid_obj = grid_obj.fit(training2, training_labels2)\n",
    "RFR = grid_obj.best_estimator_\n",
    "RFR.fit(training2, training_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw AUC score of Random Forest: 0.822767611633\n",
      "RFR validation data accuracy: 0.843150081771\n",
      "RFR development data accuracy: 0.842813547991\n",
      "C: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cheryl Zhang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "predictions = RFR.predict(testing2)\n",
    "predictions2 = RFR.predict(training2)\n",
    "best_parameters, score, _ = max(log.grid_scores_, key=lambda x: x[1])\n",
    "print('Raw AUC score of Random Forest:', score)\n",
    "print (\"RFR validation data accuracy:\", accuracy_score(testing_labels2, predictions))\n",
    "print (\"RFR development data accuracy:\", accuracy_score(training_labels2, predictions2))\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    5.0s remaining:    7.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   10.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   10.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw AUC score: 0.8808907250155672\n",
      "Xgboost validation data accuracy: 0.843150081771\n",
      "Xgboost development data accuracy: 0.842813547991\n",
      "Xgboost accuracy: 0.843150081771\n",
      "colsample_bytree: 0.7\n",
      "learning_rate: 0.05\n",
      "max_depth: 6\n",
      "min_child_weight: 11\n",
      "missing: -999\n",
      "n_estimators: 5\n",
      "nthread: 4\n",
      "objective: 'binary:logistic'\n",
      "seed: 1337\n",
      "silent: 1\n",
      "subsample: 0.8\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "#brute force scan for all parameters, here are the tricks\n",
    "#usually max_depth is 6,7,8\n",
    "#learning rate is around 0.05, but small changes may make big diff\n",
    "#tuning min_child_weight subsample colsample_bytree can have \n",
    "#much fun of fighting against overfit \n",
    "#n_estimators is how many round of boosting\n",
    "#finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "\n",
    "\n",
    "xgclf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=StratifiedKFold(training_labels2, n_folds=5, shuffle=True), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "xgclf.fit(training2, training_labels2)\n",
    "best_parameters, score, _ = max(xgclf.grid_scores_, key=lambda x: x[1])\n",
    "print('Raw AUC score:', score)\n",
    "resulttesting = xgclf.predict(testing2)\n",
    "resutlttraining = xgclf.predict(training2)\n",
    "print (\"Xgboost validation data accuracy:\", accuracy_score(testing_labels2, resulttesting))\n",
    "print (\"Xgboost development data accuracy:\", accuracy_score(training_labels2, resutlttraining))\n",
    "print (\"Xgboost accuracy:\", accuracy_score(testing_labels2, resulttesting))\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00   7.83240328e-07]\n",
      " [  0.00000000e+00   5.35214224e-06]\n",
      " [  2.68096515e-03   4.50154324e-03]\n",
      " [  0.00000000e+00   2.57163908e-05]\n",
      " [  0.00000000e+00   1.04301504e-04]\n",
      " [  0.00000000e+00   7.81934927e-05]\n",
      " [  1.06022053e-02   3.46089098e-02]\n",
      " [  0.00000000e+00   3.91620164e-07]\n",
      " [  1.36892539e-02   1.96866151e-02]\n",
      " [  0.00000000e+00   6.13538257e-06]]\n",
      "[[False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cheryl Zhang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n",
      "C:\\Users\\Cheryl Zhang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# Convert data as np.array\n",
    "features = np.array(training2)\n",
    "targets = np.array(training_labels2.reshape(training_labels2.shape[0],1))\n",
    "features_validation= np.array(testing2)\n",
    "targets_validation = np.array(testing_labels2.reshape(testing_labels2.shape[0],1))\n",
    "\n",
    "print(features[:10])\n",
    "print(targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 641\n",
      "Trainable params: 641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(training2.shape[1],)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(.1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss = 'mse', optimizer='adam', metrics=['mse']) #mse: mean_square_error\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185474/185474 [==============================] - 14s 73us/step - loss: 0.1354 - mean_squared_error: 0.1354\n",
      "Epoch 2/50\n",
      "185474/185474 [==============================] - 14s 75us/step - loss: 0.1356 - mean_squared_error: 0.1356\n",
      "Epoch 3/50\n",
      "185474/185474 [==============================] - 14s 75us/step - loss: 0.1361 - mean_squared_error: 0.1361\n",
      "Epoch 4/50\n",
      "185474/185474 [==============================] - 14s 73us/step - loss: 0.1349 - mean_squared_error: 0.1349\n",
      "Epoch 5/50\n",
      "185474/185474 [==============================] - 14s 74us/step - loss: 0.1359 - mean_squared_error: 0.1359\n",
      "Epoch 6/50\n",
      "185474/185474 [==============================] - 13s 71us/step - loss: 0.1360 - mean_squared_error: 0.1360\n",
      "Epoch 7/50\n",
      "185474/185474 [==============================] - 13s 72us/step - loss: 0.1352 - mean_squared_error: 0.1352\n",
      "Epoch 8/50\n",
      "185474/185474 [==============================] - 14s 73us/step - loss: 0.1352 - mean_squared_error: 0.1352\n",
      "Epoch 9/50\n",
      "185474/185474 [==============================] - 14s 74us/step - loss: 0.1352 - mean_squared_error: 0.1352\n",
      "Epoch 10/50\n",
      "185474/185474 [==============================] - 14s 73us/step - loss: 0.1354 - mean_squared_error: 0.1354\n",
      "Epoch 11/50\n",
      "185474/185474 [==============================] - 13s 72us/step - loss: 0.1356 - mean_squared_error: 0.1356\n",
      "Epoch 12/50\n",
      "185474/185474 [==============================] - 14s 73us/step - loss: 0.1354 - mean_squared_error: 0.1354\n",
      "Epoch 13/50\n",
      "185474/185474 [==============================] - 13s 70us/step - loss: 0.1357 - mean_squared_error: 0.1357\n",
      "Epoch 14/50\n",
      "185474/185474 [==============================] - 14s 74us/step - loss: 0.1354 - mean_squared_error: 0.1354\n",
      "Epoch 15/50\n",
      "185474/185474 [==============================] - 13s 72us/step - loss: 0.1357 - mean_squared_error: 0.1357\n",
      "Epoch 16/50\n",
      "185474/185474 [==============================] - 15s 79us/step - loss: 0.1348 - mean_squared_error: 0.1348\n",
      "Epoch 17/50\n",
      "185474/185474 [==============================] - 13s 73us/step - loss: 0.1357 - mean_squared_error: 0.1357\n",
      "Epoch 18/50\n",
      "185474/185474 [==============================] - 14s 76us/step - loss: 0.1350 - mean_squared_error: 0.1350\n",
      "Epoch 19/50\n",
      "185474/185474 [==============================] - 14s 73us/step - loss: 0.1355 - mean_squared_error: 0.1355\n",
      "Epoch 20/50\n",
      "185474/185474 [==============================] - 13s 72us/step - loss: 0.1354 - mean_squared_error: 0.1354\n",
      "Epoch 21/50\n",
      "185474/185474 [==============================] - 14s 74us/step - loss: 0.1353 - mean_squared_error: 0.1353\n",
      "Epoch 22/50\n",
      "185474/185474 [==============================] - 13s 71us/step - loss: 0.1367 - mean_squared_error: 0.1367\n",
      "Epoch 23/50\n",
      "185474/185474 [==============================] - 14s 74us/step - loss: 0.1353 - mean_squared_error: 0.1353\n",
      "Epoch 24/50\n",
      "185474/185474 [==============================] - 13s 69us/step - loss: 0.1352 - mean_squared_error: 0.1352\n",
      "Epoch 25/50\n",
      "185474/185474 [==============================] - 13s 70us/step - loss: 0.1354 - mean_squared_error: 0.1354\n",
      "Epoch 26/50\n",
      "185474/185474 [==============================] - 12s 66us/step - loss: 0.1354 - mean_squared_error: 0.1354\n",
      "Epoch 27/50\n",
      "185474/185474 [==============================] - 15s 83us/step - loss: 0.1352 - mean_squared_error: 0.1352\n",
      "Epoch 28/50\n",
      "185474/185474 [==============================] - 13s 68us/step - loss: 0.1352 - mean_squared_error: 0.1352\n",
      "Epoch 29/50\n",
      "185474/185474 [==============================] - 13s 67us/step - loss: 0.1361 - mean_squared_error: 0.1361\n",
      "Epoch 30/50\n",
      "185474/185474 [==============================] - 13s 69us/step - loss: 0.1353 - mean_squared_error: 0.1353\n",
      "Epoch 31/50\n",
      "185474/185474 [==============================] - 13s 72us/step - loss: 0.1356 - mean_squared_error: 0.1356\n",
      "Epoch 32/50\n",
      "185474/185474 [==============================] - 12s 65us/step - loss: 0.1356 - mean_squared_error: 0.1356\n",
      "Epoch 33/50\n",
      "185474/185474 [==============================] - 12s 67us/step - loss: 0.1349 - mean_squared_error: 0.1349\n",
      "Epoch 34/50\n",
      "185474/185474 [==============================] - 13s 70us/step - loss: 0.1354 - mean_squared_error: 0.1354\n",
      "Epoch 35/50\n",
      "185474/185474 [==============================] - 13s 72us/step - loss: 0.1359 - mean_squared_error: 0.1359\n",
      "Epoch 36/50\n",
      "185474/185474 [==============================] - 12s 64us/step - loss: 0.1352 - mean_squared_error: 0.1352\n",
      "Epoch 37/50\n",
      "185474/185474 [==============================] - 12s 67us/step - loss: 0.1356 - mean_squared_error: 0.1356\n",
      "Epoch 38/50\n",
      "185474/185474 [==============================] - 12s 67us/step - loss: 0.1356 - mean_squared_error: 0.1356\n",
      "Epoch 39/50\n",
      "185474/185474 [==============================] - 12s 67us/step - loss: 0.1351 - mean_squared_error: 0.1351\n",
      "Epoch 40/50\n",
      "185474/185474 [==============================] - 13s 68us/step - loss: 0.1350 - mean_squared_error: 0.1350\n",
      "Epoch 41/50\n",
      "185474/185474 [==============================] - 12s 65us/step - loss: 0.1364 - mean_squared_error: 0.1364\n",
      "Epoch 42/50\n",
      "185474/185474 [==============================] - 13s 69us/step - loss: 0.1356 - mean_squared_error: 0.1356\n",
      "Epoch 43/50\n",
      "185474/185474 [==============================] - 13s 68us/step - loss: 0.1357 - mean_squared_error: 0.1357\n",
      "Epoch 44/50\n",
      "185474/185474 [==============================] - 13s 68us/step - loss: 0.1348 - mean_squared_error: 0.1348\n",
      "Epoch 45/50\n",
      "185474/185474 [==============================] - 12s 66us/step - loss: 0.1350 - mean_squared_error: 0.1350\n",
      "Epoch 46/50\n",
      "185474/185474 [==============================] - 13s 69us/step - loss: 0.1356 - mean_squared_error: 0.1356\n",
      "Epoch 47/50\n",
      "185474/185474 [==============================] - 13s 71us/step - loss: 0.1373 - mean_squared_error: 0.1373\n",
      "Epoch 48/50\n",
      "185474/185474 [==============================] - 13s 68us/step - loss: 0.1358 - mean_squared_error: 0.1358\n",
      "Epoch 49/50\n",
      "185474/185474 [==============================] - 12s 66us/step - loss: 0.1361 - mean_squared_error: 0.1361\n",
      "Epoch 50/50\n",
      "185474/185474 [==============================] - 12s 63us/step - loss: 0.1349 - mean_squared_error: 0.1349\n",
      "R2 score =  0.490521224666 / 1.0\n"
     ]
    }
   ],
   "source": [
    "model.fit(training2, training_labels2, batch_size = 32, epochs = 50)\n",
    "predictions = model.predict(features_validation, verbose=0)\n",
    "print('R2 score = ',r2_score(testing_labels2, predictions), '/ 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svm = SVC()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':(1,0.25,0.5,0.75),'gamma': (1,2,3,'auto'),'decision_function_shape':('ovo','ovr'),'shrinking':(True,False)}\n",
    "svmclf = GridSearchCV(svm, parameters)\n",
    "svmclf.fit(training1,training_labels1)\n",
    "print(\"accuracy:\"+str(np.average(cross_val_score(svmclf, training1, training_labels1, scoring='accuracy'))))\n",
    "print(\"f1:\"+str(np.average(cross_val_score(svmclf, training1, training_labels1, scoring='f1'))))\n",
    "resulttesting = svmclf.predict(testing1)\n",
    "resutlttraining = svmclf.predict(training1)\n",
    "print (\"LogisticRegression validation data accuracy:\", accuracy_score(testing_labels1, resulttesting))\n",
    "print (\"LogisticRegression development data accuracy:\", accuracy_score(training_labels1, resutlttraining))\n",
    "best_parameters, score, _ = max(log.grid_scores_, key=lambda x: x[1])\n",
    "print('Raw AUC score:', score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   source   target        aa  common\n",
      "0           0  2184483  1300190  0.000000       0\n",
      "1           1  3151356  1452193  0.407705       4\n",
      "2           2  1579396   193159  0.000000       0\n",
      "3           3  1406432  2481036  1.238898       7\n",
      "4           4  2389638   593017  0.802812       6\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "pd.read_table('C:/Users/Cheryl Zhang/Desktop/pred.txt', sep = '\\t')\n",
    "pdtable = pd.read_table('C:/Users/Cheryl Zhang/Desktop/pred.txt', sep = '\\t')\n",
    "print(pdtable[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common</th>\n",
       "      <th>AdamicAdar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.407705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Common  AdamicAdar\n",
       "0       0    0.000000\n",
       "1       4    0.407705\n",
       "2       0    0.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pdtable[['common', 'aa']]\n",
    "len(pred)\n",
    "pred.columns = ['Common', 'AdamicAdar']\n",
    "pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.43541113  0.56757724  0.43541113]\n"
     ]
    }
   ],
   "source": [
    "test_probs = clf.predict_proba(pred)[:,1]\n",
    "print(test_probs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25724323  0.09355926  0.25724323]\n"
     ]
    }
   ],
   "source": [
    "preprob = log.predict_proba(pred)[:,1]\n",
    "print(preprob[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('C:/Users/Cheryl Zhang/Desktop/sample.csv')\n",
    "sample.Prediction = test_probs\n",
    "sample.to_csv(\"submissionxgboost.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample.Prediction = preprob\n",
    "sample.to_csv(\"submissionlog.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
